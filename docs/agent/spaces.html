<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-agent/spaces" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Defining Spaces | NovelGym</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://novelgym.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://novelgym.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://novelgym.github.io/docs/agent/spaces"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Defining Spaces | NovelGym"><meta data-rh="true" name="description" content="Observation Space"><meta data-rh="true" property="og:description" content="Observation Space"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://novelgym.github.io/docs/agent/spaces"><link data-rh="true" rel="alternate" href="https://novelgym.github.io/docs/agent/spaces" hreflang="en"><link data-rh="true" rel="alternate" href="https://novelgym.github.io/docs/agent/spaces" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.e3452f36.css">
<script src="/assets/js/runtime~main.25bad449.js" defer="defer"></script>
<script src="/assets/js/main.02b7bc1d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="NovelGym Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="NovelGym Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">NovelGym</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/install">Guide</a><a href="https://github.com/tufts-ai-robotics-group/NovelGym" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/install">Installation</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/customizing-environments">Customizing Environments</a><button aria-label="Expand sidebar category &#x27;Customizing Environments&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/training-agents">Training Agents</a><button aria-label="Collapse sidebar category &#x27;Training Agents&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/agent/spaces">Defining Spaces</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/agent/combining">Combining Planning &amp; RL Agents</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/references">References</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/training-agents"><span itemprop="name">Training Agents</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Defining Spaces</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Defining Spaces</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="observation-space">Observation Space<a href="#observation-space" class="hash-link" aria-label="Direct link to Observation Space" title="Direct link to Observation Space">​</a></h2>
<p>The implementations of the observation spaces are in the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/tree/main/obs_convertion" target="_blank" rel="noopener noreferrer">obs_convertion</a> folder. The base class is <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/base.py" target="_blank" rel="noopener noreferrer">ObservationGenerator</a>, which outlines methods to be implemented in an observation space. See the diagram below for the full class interdependence.</p>
<p><img loading="lazy" alt="Observations" src="/assets/images/Observations.drawio-c38e08243c7ec515815cbea3184b5854.png" width="1703" height="409" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="currently-implemented">Currently Implemented<a href="#currently-implemented" class="hash-link" aria-label="Direct link to Currently Implemented" title="Direct link to Currently Implemented">​</a></h3>
<p>All of the currently implemented observation spaces are gymnasium Box spaces. The <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/lidar_all.py" target="_blank" rel="noopener noreferrer">LidarAll</a> class has a single Box space made from a one-dimensional vector with the item selected by the agent, the agent&#x27;s inventory, and the euclidean distances to the objects that strike the LiDAR beam sent by the agent in 45 degree increments. The children <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/only_facing.py" target="_blank" rel="noopener noreferrer">OnlyFacingObs</a> and <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/only_hinted.py" target="_blank" rel="noopener noreferrer">NovelOnlyObs</a> limit the number of LiDAR beams sent and the types of objects detected respectively. The child <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/matrix.py" target="_blank" rel="noopener noreferrer">Matrix</a> holds a dictionary with three Box spaces, one for the agent&#x27;s selected item, one for the agent&#x27;s inventory, and one for the agent&#x27;s local view, stored as a two-dimensional square image.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="adding-new">Adding New<a href="#adding-new" class="hash-link" aria-label="Direct link to Adding New" title="Direct link to Adding New">​</a></h3>
<p>The easiest way of adding a new observation space is by declaring a child of <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/lidar_all.py" target="_blank" rel="noopener noreferrer">LidarAll</a> and overriding those parts of the parent class that differ in the theoretical new observation space. The more complex part is integrating the new space in training. If the structure of the new space differs from that under <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/lidar_all.py" target="_blank" rel="noopener noreferrer">LidarAll</a>, a compatible net must be added to the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/tree/main/net" target="_blank" rel="noopener noreferrer">net</a> folder, a new policy implemented in the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/policy_utils.py" target="_blank" rel="noopener noreferrer">policy_utils.py</a> file, and a case added to the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/train.py" target="_blank" rel="noopener noreferrer">train.py</a> so that the right policy-maker is called instead of <code>create_policy</code> when the new observation space is being used.</p>
<p>Any newly implemented observation space should be placed in the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/tree/main/obs_convertion" target="_blank" rel="noopener noreferrer">obs_convertion</a> folder, listed in the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/obs_convertion/__init__.py" target="_blank" rel="noopener noreferrer">obs_convertion/__init__.py</a> file consistent with the spaces already there, and included under <code>OBS_TYPES</code> in <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/36f78f5e25475a43a8a83627939a5744d0a42c0c/config.py" target="_blank" rel="noopener noreferrer">config.py</a> so that the space can be chosen when training is being run from the command line.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="action-space">Action Space<a href="#action-space" class="hash-link" aria-label="Direct link to Action Space" title="Direct link to Action Space">​</a></h2>
<p>The agent&#x27;s action space is automatically generated from the config file and no advanced modifications are required when integrating new actions. However, one may wish to modify or override the <code>action_space</code> method of the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/main/envs/single_agent_standard.py" target="_blank" rel="noopener noreferrer">SingleAgentWrapper</a> class, explored in the <a href="/docs/agent/combining">Combining Planning &amp; RL Agents</a> part of the tutorial.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="reward-function">Reward Function<a href="#reward-function" class="hash-link" aria-label="Direct link to Reward Function" title="Direct link to Reward Function">​</a></h2>
<p>The reward is generated from the above-described observation module by the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/blob/36f78f5e25475a43a8a83627939a5744d0a42c0c/envs/single_agent_standard.py" target="_blank" rel="noopener noreferrer">SingleAgentWrapper</a> and passed to the integrated external RL agent. Additional reward generation occurs in the reward-shaping and neurosymbolics wrappers, found in the <a href="https://github.com/tufts-ai-robotics-group/NovelGym/tree/main/envs" target="_blank" rel="noopener noreferrer">envs</a> folder and described in detail in the <a href="/docs/agent/combining">Combining Planning &amp; RL Agents</a> part of the tutorial.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/category/training-agents"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Training Agents</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/agent/combining"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Combining Planning &amp; RL Agents</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#observation-space" class="table-of-contents__link toc-highlight">Observation Space</a><ul><li><a href="#currently-implemented" class="table-of-contents__link toc-highlight">Currently Implemented</a></li><li><a href="#adding-new" class="table-of-contents__link toc-highlight">Adding New</a></li></ul></li><li><a href="#action-space" class="table-of-contents__link toc-highlight">Action Space</a></li><li><a href="#reward-function" class="table-of-contents__link toc-highlight">Reward Function</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 NovelGym Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>