"use strict";(self.webpackChunkng_website=self.webpackChunkng_website||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Installation","href":"/docs/install","docId":"install","unlisted":false},{"type":"category","label":"Customizing Environments","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Running Example","href":"/docs/environment/running","docId":"environment/running","unlisted":false},{"type":"link","label":"Keyboard Demo","href":"/docs/environment/demo","docId":"environment/demo","unlisted":false},{"type":"link","label":"Creating Your Environment","href":"/docs/environment/custom","docId":"environment/custom","unlisted":false},{"type":"link","label":"Implementing Novelties","href":"/docs/environment/novelty","docId":"environment/novelty","unlisted":false},{"type":"link","label":"Examples of Objects & Actions","href":"/docs/environment/objectsactions","docId":"environment/objectsactions","unlisted":false}],"href":"/docs/category/customizing-environments"},{"type":"category","label":"Training Agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Defining Spaces","href":"/docs/agent/spaces","docId":"agent/spaces","unlisted":false},{"type":"link","label":"Combining Planning & RL Agents","href":"/docs/agent/combining","docId":"agent/combining","unlisted":false}],"href":"/docs/category/training-agents"},{"type":"link","label":"References","href":"/docs/references","docId":"references","unlisted":false}]},"docs":{"agent/combining":{"id":"agent/combining","title":"Combining Planning & RL Agents","description":"The agent training architecture is made up of the single agent wrapper, the neurosymbolic wrapper, and the reward-shaping wrapper, all of which can be found in the envs folder. The wrappers responsible for combining the symbolic planning and reinforcement learning agents are the neurosymbolic wrapper and the reward-shaping wrapper.","sidebar":"tutorialSidebar"},"agent/spaces":{"id":"agent/spaces","title":"Defining Spaces","description":"Observation Space","sidebar":"tutorialSidebar"},"environment/custom":{"id":"environment/custom","title":"Creating Your Environment","description":"In this section, we look at the polycraftgymmain.yaml config used in the following three files:","sidebar":"tutorialSidebar"},"environment/demo":{"id":"environment/demo","title":"Keyboard Demo","description":"To get a feel for the game the agent will learn, run the following command from the root of the NovelGym repository.","sidebar":"tutorialSidebar"},"environment/novelty":{"id":"environment/novelty","title":"Implementing Novelties","description":"To implement a novelty, you need a config file and optionally one or more python files, such as when a new object or action is being introduced. To see how these files are integrated in the project structure, go to novelties/evaluation1.","sidebar":"tutorialSidebar"},"environment/objectsactions":{"id":"environment/objectsactions","title":"Examples of Objects & Actions","description":"The implementations of the objects and actions for the base environment are in the NovelGridWorldsV2 repository, which you will have installed in Installation. In this section, we explore how the individual object and action classes relate to each other and how a specific object or action is implemented and integrated.","sidebar":"tutorialSidebar"},"environment/running":{"id":"environment/running","title":"Running Example","description":"This section includes a description of the rules and goal of the game in the environment implemented in NovelGym. The image below is for illustrative purposes only and does not represent the actual rendering.","sidebar":"tutorialSidebar"},"install":{"id":"install","title":"Installation","description":"The instructions below match those in the GitHub repository.","sidebar":"tutorialSidebar"},"references":{"id":"references","title":"References","description":"","sidebar":"tutorialSidebar"}}}')}}]);