"use strict";(self.webpackChunkng_website=self.webpackChunkng_website||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Installation","href":"/docs/install","docId":"install","unlisted":false},{"type":"category","label":"Customizing Environments","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Keyboard Demo","href":"/docs/environment/demo","docId":"environment/demo","unlisted":false},{"type":"link","label":"Creating Your Environment","href":"/docs/environment/custom","docId":"environment/custom","unlisted":false},{"type":"link","label":"Implementing Novelties","href":"/docs/environment/novelty","docId":"environment/novelty","unlisted":false},{"type":"link","label":"Examples of Objects & Actions","href":"/docs/environment/objectsactions","docId":"environment/objectsactions","unlisted":false}],"href":"/docs/category/customizing-environments"},{"type":"category","label":"Training Agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Defining Spaces","href":"/docs/agent/spaces","docId":"agent/spaces","unlisted":false},{"type":"link","label":"Combining Planning & RL Agents","href":"/docs/agent/combining","docId":"agent/combining","unlisted":false}],"href":"/docs/category/training-agents"},{"type":"link","label":"References","href":"/docs/references","docId":"references","unlisted":false}]},"docs":{"agent/combining":{"id":"agent/combining","title":"Combining Planning & RL Agents","description":"The agent training architecture is made up of the single agent wrapper, the neurosymbolic wrapper, and the reward-shaping wrapper, all of which can be found in the envs folder. The wrappers responsible for combining the symbolic planning and reinforcement learning agents are the neurosymbolic wrapper and the reward-shaping wrapper.","sidebar":"tutorialSidebar"},"agent/spaces":{"id":"agent/spaces","title":"Defining Spaces","description":"Observation Space","sidebar":"tutorialSidebar"},"environment/custom":{"id":"environment/custom","title":"Creating Your Environment","description":"In the previous part of the tutorial, Keyboard Demo, we ran the script manualnoveltytest1.py to try out the keyboard agent for the NovelGym environment. Like manualsanitychecker.py, the script designed for loading a trained model and seeing what action the model selects, and train.py, the script used for training, manualnoveltytest1.py creates the environment from the polycraftgymmain.yaml config file.","sidebar":"tutorialSidebar"},"environment/demo":{"id":"environment/demo","title":"Keyboard Demo","description":"To gain an intuition behind the game the agent will be taught to play, run the following command from the root of the NovelGym repository.","sidebar":"tutorialSidebar"},"environment/novelty":{"id":"environment/novelty","title":"Implementing Novelties","description":"Two components are required for novelty implementation, namely a config file and optionally one or more python files, such as when a new object or action is being introduced. To see how these files are integrated in the project structure, go to novelties/evaluation1.","sidebar":"tutorialSidebar"},"environment/objectsactions":{"id":"environment/objectsactions","title":"Examples of Objects & Actions","description":"The implementations of the objects and actions for the base environment are in the NovelGridWorldsV2 repository, which you will have installed together with its wrapper repository NovelGym. In this part of the tutorial, we explore how the individual object and action classes relate to each other and how a specific object or action is implemented and integrated in the infrastructure.","sidebar":"tutorialSidebar"},"install":{"id":"install","title":"Installation","description":"The instructions below match those in the GitHub repository.","sidebar":"tutorialSidebar"},"references":{"id":"references","title":"References","description":"","sidebar":"tutorialSidebar"}}}')}}]);